{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMxscX3POww1Hmf42/GYfBd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sowmyavyk/Bot-LLM/blob/master/Video_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms, models\n",
        "import os\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import pipeline\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import nltk\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Configuration\n",
        "PARTS_DIR = \"/content/images\"\n",
        "EXPLANATION_TEXT = \"\"\"\n",
        "    Once the model has been setup as per the instruction manual, connect the battery as indicated next to the DPDT terminals.\n",
        "\n",
        "    As the supply from the battery starts, the force generated by the DC motor rotates the connected gears. This turning of the gear, in turn rotates the associated gear and pulls the weight against gravity. Electric energy is converted to mechanical energy during this process because it involves movement caused by a force generated by a DC motor .\n",
        "\n",
        "    The DC motor in the model also works as a generator here, lets see how?\n",
        "\n",
        "    When the supply from the battery is turned off, the force of gravity acts on the weight and causes the gears to rotate in another direction. The DC motor contains coils of wire and magnets, when the gear turns, it makes the coils of wire spin inside the magnetic field created by the magnets.This spinning motion induces an electric current to flow through the wires into the LED ,which glows!! Converting the mechanical energy of the gear rotation into the electrical energy through the generator.\n",
        "\n",
        "    This way! We can harness the force of gravity to generate electricity.\"\"\"\n",
        "\n",
        "class EnhancedPartClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.model = models.resnet18(pretrained=True)\n",
        "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "class PartDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        images = sorted([f for f in os.listdir(root_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
        "        for idx, filename in enumerate(images):\n",
        "            self.image_paths.append(os.path.join(root_dir, filename))\n",
        "            self.labels.append(idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, self.labels[idx]\n",
        "\n",
        "class VideoUnderstandingSystem:\n",
        "    def __init__(self, parts_dir, explanation_text):\n",
        "        self.parts_dir = parts_dir\n",
        "        self.explanation_text = explanation_text\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # Image preprocessing transforms\n",
        "        self.classifier_transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        # Initialize components\n",
        "        self.component_db = self.create_component_database()\n",
        "        self.classifier = self.train_part_classifier()\n",
        "        self.qa_processor = self.create_knowledge_graph()\n",
        "\n",
        "        # Separate feature extractor for images\n",
        "        self.image_feature_extractor = models.resnet18(pretrained=True).to(self.device)\n",
        "        self.image_feature_extractor.eval()\n",
        "\n",
        "        # Text feature extractor\n",
        "        self.text_feature_extractor = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "        # Question generator\n",
        "        self.question_generator = pipeline(\n",
        "            \"text2text-generation\",\n",
        "            model=\"mrm8488/t5-base-finetuned-question-generation-ap\",\n",
        "            device=0 if torch.cuda.is_available() else -1,\n",
        "            num_beams=4,\n",
        "            do_sample=True,\n",
        "            temperature=0.7\n",
        "        )\n",
        "\n",
        "    def train_part_classifier(self):\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.RandomRotation(30),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        dataset = PartDataset(PARTS_DIR, transform=transform)\n",
        "        loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "        model = EnhancedPartClassifier(len(dataset)).to(self.device)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(15):\n",
        "            model.train()\n",
        "            for images, labels in loader:\n",
        "                images, labels = images.to(self.device), labels.to(self.device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        return model.eval()\n",
        "    def analyze_movement(self, prev_detection, current_detection):\n",
        "        \"\"\"Simple movement analysis between frames\"\"\"\n",
        "        if prev_detection['part_id'] == current_detection['part_id']:\n",
        "            return \"Stationary\" if abs(current_detection['similarity'] - prev_detection['similarity']) < 0.1 else \"Moving\"\n",
        "        return \"Different component detected\"\n",
        "\n",
        "    def get_image_features(self, image):\n",
        "        \"\"\"Extract features using ResNet18\"\"\"\n",
        "        if isinstance(image, Image.Image):\n",
        "            image = self.classifier_transform(image).unsqueeze(0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            features = self.image_feature_extractor(image.to(self.device))\n",
        "        return features.squeeze()\n",
        "\n",
        "    def compare_with_reference(self, image, part_id):\n",
        "        \"\"\"Compare with reference image using ResNet features\"\"\"\n",
        "        try:\n",
        "            # Process input image\n",
        "            query_features = self.get_image_features(image)\n",
        "\n",
        "            # Load reference image\n",
        "            ref_path = os.path.join(self.parts_dir, f\"{part_id}.jpg\")\n",
        "            if not os.path.exists(ref_path):\n",
        "                return 0.0\n",
        "\n",
        "            ref_image = Image.open(ref_path).convert('RGB')\n",
        "            ref_features = self.get_image_features(ref_image)\n",
        "\n",
        "            # Calculate cosine similarity\n",
        "            cos_sim = torch.nn.CosineSimilarity(dim=0)\n",
        "            return cos_sim(query_features, ref_features).item()\n",
        "        except Exception as e:\n",
        "            print(f\"Error comparing images: {e}\")\n",
        "            return 0.0\n",
        "\n",
        "    def create_component_database(self):\n",
        "        return {\n",
        "          \"part_01\": {\n",
        "              \"name\": \"DC Motor/Generator\",\n",
        "              \"function\": \"Converts electrical energy to mechanical energy and vice versa\",\n",
        "              \"video_behavior\": \"Rotates when powered, generates electricity when spun\"\n",
        "          },\n",
        "          \"part_02\": {\n",
        "              \"name\": \"Battery\",\n",
        "              \"function\": \"Provides electrical power to the system\",\n",
        "              \"video_behavior\": \"Supplies energy to the circuit, enabling the motor to rotate\"\n",
        "          },\n",
        "          \"part_03\": {\n",
        "              \"name\": \"LED Indicator\",\n",
        "              \"function\": \"Indicates power status or voltage level\",\n",
        "              \"video_behavior\": \"Glows when the circuit is complete and power is supplied\"\n",
        "          },\n",
        "          \"part_04\": {\n",
        "              \"name\": \"Switch\",\n",
        "              \"function\": \"Controls the flow of electricity in the circuit\",\n",
        "              \"video_behavior\": \"Turns the motor on or off when toggled\"\n",
        "          },\n",
        "          \"part_05\": {\n",
        "              \"name\": \"Resistor\",\n",
        "              \"function\": \"Limits current flow and protects components\",\n",
        "              \"video_behavior\": \"Remains stationary, ensures stable current supply\"\n",
        "          }\n",
        "      }\n",
        "\n",
        "    def create_knowledge_graph(self):\n",
        "        sentences = nltk.sent_tokenize(self.explanation_text)\n",
        "        cleaned_sentences = [s.strip() for s in sentences if len(s) > 15]\n",
        "\n",
        "        for part in self.component_db.values():\n",
        "            cleaned_sentences.append(f\"{part['name']}: {part['function']}\")\n",
        "            cleaned_sentences.append(f\"Behavior: {part['video_behavior']}\")\n",
        "\n",
        "        return QAProcessor(cleaned_sentences)\n",
        "\n",
        "    def analyze_video(self, video_path):\n",
        "      cap = cv2.VideoCapture(video_path)\n",
        "      results = []\n",
        "\n",
        "      if not cap.isOpened():\n",
        "          raise ValueError(f\"Could not open video file: {video_path}\")\n",
        "\n",
        "      try:\n",
        "          while cap.isOpened():\n",
        "              ret, frame = cap.read()\n",
        "              if not ret:\n",
        "                  break\n",
        "\n",
        "              pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "              detection = self.detect_components(pil_img)\n",
        "\n",
        "              if len(results) > 0:\n",
        "                  detection['movement'] = self.analyze_movement(results[-1], detection)\n",
        "\n",
        "              results.append(detection)\n",
        "      except Exception as e:\n",
        "          print(f\"Error processing video: {e}\")\n",
        "      finally:\n",
        "          cap.release()\n",
        "\n",
        "      if not results:\n",
        "          print(\"No frames processed. Check video file format and contents.\")\n",
        "\n",
        "      return results\n",
        "\n",
        "    def detect_components(self, image):\n",
        "        transformed = self.classifier_transform(image).unsqueeze(0).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.classifier(transformed)\n",
        "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
        "            conf, pred = torch.max(probs, 1)\n",
        "\n",
        "        part_id = f\"part_{pred.item()+1:02d}\"\n",
        "        return {\n",
        "            'part_id': part_id,\n",
        "            'confidence': conf.item(),\n",
        "            'component_info': self.component_db.get(part_id, {}),\n",
        "            'similarity': self.compare_with_reference(image, part_id)\n",
        "        }\n",
        "    def generate_questions(self, num=5):\n",
        "        # Context-aware question generation\n",
        "        return self.question_generator(\n",
        "            \"Generate technical questions about this physics demonstration: \" + self.explanation_text,\n",
        "            max_length=128,\n",
        "            num_return_sequences=num,\n",
        "            temperature=0.9,\n",
        "            repetition_penalty=2.0\n",
        "        )\n",
        "\n",
        "    # Rest of the methods...\n",
        "\n",
        "class QAProcessor:\n",
        "    def __init__(self, knowledge_base):\n",
        "        self.model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "        self.knowledge = knowledge_base\n",
        "        self.embeddings = self.model.encode(self.knowledge)\n",
        "\n",
        "    def answer_question(self, question):\n",
        "        question_embed = self.model.encode(question)\n",
        "        scores = util.cos_sim(question_embed, self.embeddings)[0]\n",
        "        top_3 = torch.topk(scores, k=3)\n",
        "        return \"\\n\".join([self.knowledge[i] for i in top_3.indices])\n",
        "\n",
        "def main():\n",
        "    system = VideoUnderstandingSystem(PARTS_DIR, EXPLANATION_TEXT)\n",
        "\n",
        "    # Example usage\n",
        "    video_results = system.analyze_video(\"/content/video.mp4\")\n",
        "    print(\"First frame:\", video_results[0])\n",
        "\n",
        "    questions = system.generate_questions(3)\n",
        "    print(\"\\nGenerated Questions:\")\n",
        "    for i, q in enumerate(questions, 1):\n",
        "        print(f\"{i}. {q['generated_text']}\")\n",
        "\n",
        "    # Q&A loop\n",
        "    while True:\n",
        "        question = input(\"\\nAsk about the system (q to quit): \")\n",
        "        if question.lower() == 'q':\n",
        "            break\n",
        "        print(\"Answer:\", system.qa_processor.answer_question(question))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuLEfutiQ0pE",
        "outputId": "3507c6aa-ab73-4d73-9697-d7a22e7d287e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First frame: {'part_id': 'part_04', 'confidence': 0.43060410022735596, 'component_info': {'name': 'Switch', 'function': 'Controls the flow of electricity in the circuit', 'video_behavior': 'Turns the motor on or off when toggled'}, 'similarity': 0.0}\n",
            "\n",
            "Generated Questions:\n",
            "1. question: What are the technical questions about this model?\n",
            "2. question: What are the technical questions about the DC motor?\n",
            "3. question: What are the technical questions about the model?\n",
            "\n",
            "Ask about the system (q to quit): WHAT DOES THE MOTOR DOES IN THIS MODEL\n",
            "Answer: The DC motor in the model also works as a generator here, lets see how?\n",
            "Behavior: Supplies energy to the circuit, enabling the motor to rotate\n",
            "DC Motor/Generator: Converts electrical energy to mechanical energy and vice versa\n",
            "\n",
            "Ask about the system (q to quit): WHAT IS WEIGHT DOING IN THIS\n",
            "Answer: This turning of the gear, in turn rotates the associated gear and pulls the weight against gravity.\n",
            "When the supply from the battery is turned off, the force of gravity acts on the weight and causes the gears to rotate in another direction.\n",
            "Electric energy is converted to mechanical energy during this process because it involves movement caused by a force generated by a DC motor .\n",
            "\n",
            "Ask about the system (q to quit): q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GkfViLFnhGNQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}